{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cart-Pole Fixed Policy #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy ##\n",
    "\n",
    "The main variables determining how we balance the pole are: the angle at which the pole is located and the speed the pole is moving at.  If the pole is too slanted or moving too fast, we must quickly correct.  However, this is only true if both the angle and speed coincide, or in other words if they have the same magnitude.  Therefore, the policy takes these two values into account to determine whether to push left or right.  If the pole is falling to the right at a certain speed, and it surpasses a certain angle, we will push the cart to the right to balance this out.  If the pole is falling to the left and has surpassed a certain angle, we will push the cart to the left.  Otherwise, we do not need to push the cart, but since there is no idling option here, we randomly select to push either left or right.\n",
    "\n",
    "The values were selected based on trial and error.  Originally, since the speed could theoretially be infinite and the angle could be at most 24 degrees in either direction, whole integer values were selected as thresholds.  However, I found that the cart-pole is very sensitive to even the smallest of changes, with a greater emphasis on the angle of the pole, so I selected these small values, with the threshold for the pole speed doubled relative to the angle to reflect that we are allowed more leeway when it comes to the speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action(pole_angle, pole_velocity):\n",
    "    if(pole_velocity > 0.002 and pole_angle > 0.001):\n",
    "        return 1\n",
    "    elif(pole_velocity < -0.002 and pole_angle < -0.001):\n",
    "        return 0\n",
    "    else:\n",
    "        return random.randint(0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes = 100\n",
    "steps = 200\n",
    "\n",
    "reward_list = []\n",
    "for episode in range(1, episodes + 1):\n",
    "    initial_state = env.reset()\n",
    "    total_reward = 0\n",
    "    cur_action = get_action(initial_state[2], initial_state[3])\n",
    "    for step in range(1, steps + 1):\n",
    "        next_state, reward, done, _ = env.step(cur_action)\n",
    "        total_reward += reward\n",
    "        if done: break\n",
    "        state = next_state\n",
    "        cur_action = get_action(next_state[2], next_state[3])\n",
    "        #env.render()\n",
    "    reward_list.append(total_reward)\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results ##\n",
    "\n",
    "Based on the description in OpenAI, this problem is considered solved when the average timesteps over 100 runs is greater than or equal to 195."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max/Avg/Min timesteps the pole was balanced for:\n",
      "200.0 200.0 200.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Max/Avg/Min timesteps the pole was balanced for:\")\n",
    "print(np.max(reward_list), np.average(reward_list), np.min(reward_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
